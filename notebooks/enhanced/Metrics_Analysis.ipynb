{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/enhanced/Metrics_Analysis.ipynb\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "# WGAN-GP Metrics Analysis\n",
    "Comprehensive analysis of training metrics and generation quality.\n",
    "\n",
    "## Contents:\n",
    "1. Training Metrics Analysis\n",
    "2. Distribution Analysis\n",
    "3. Feature-wise Analysis\n",
    "4. Quality Metrics\n",
    "5. Cross-validation Results\n",
    "\"\"\"\n",
    "\n",
    "# %% Setup\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import torch\n",
    "\n",
    "from src.utils.enhanced.evaluation import compute_statistics\n",
    "from src.validation.metrics_tracking import MetricsTracker\n",
    "\n",
    "# %% Training Metrics Analysis\n",
    "def analyze_training_metrics(metrics_tracker):\n",
    "    \"\"\"\n",
    "    Analyze training metrics with detailed visualizations.\n",
    "    \n",
    "    Args:\n",
    "        metrics_tracker: MetricsTracker instance containing training history\n",
    "    \"\"\"\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Loss trajectories\n",
    "    axes[0,0].plot(metrics_tracker.metrics['generator_loss'], \n",
    "                   label='Generator')\n",
    "    axes[0,0].plot(metrics_tracker.metrics['critic_loss'], \n",
    "                   label='Critic')\n",
    "    axes[0,0].set_title('Loss Trajectories')\n",
    "    axes[0,0].legend()\n",
    "    \n",
    "    # Loss distributions\n",
    "    sns.histplot(metrics_tracker.metrics['generator_loss'], \n",
    "                 ax=axes[0,1], label='Generator', alpha=0.5)\n",
    "    sns.histplot(metrics_tracker.metrics['critic_loss'], \n",
    "                 ax=axes[0,1], label='Critic', alpha=0.5)\n",
    "    axes[0,1].set_title('Loss Distributions')\n",
    "    \n",
    "    # Gradient penalty\n",
    "    axes[1,0].plot(metrics_tracker.metrics['gradient_penalty'])\n",
    "    axes[1,0].set_title('Gradient Penalty')\n",
    "    \n",
    "    # Wasserstein distance\n",
    "    axes[1,1].plot(metrics_tracker.metrics['wasserstein_distance'])\n",
    "    axes[1,1].set_title('Wasserstein Distance')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# %% Distribution Analysis\n",
    "def analyze_distributions(original_data, generated_data):\n",
    "    \"\"\"\n",
    "    Analyze statistical distributions of original and generated data.\n",
    "    \n",
    "    Args:\n",
    "        original_data: Original control samples\n",
    "        generated_data: Generated synthetic samples\n",
    "    \"\"\"\n",
    "    # Statistical tests\n",
    "    ks_stats = []\n",
    "    p_values = []\n",
    "    \n",
    "    for col in original_data.columns:\n",
    "        stat, p = stats.ks_2samp(original_data[col], \n",
    "                                generated_data[col])\n",
    "        ks_stats.append(stat)\n",
    "        p_values.append(p)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # KS statistics\n",
    "    sns.histplot(ks_stats, ax=axes[0,0])\n",
    "    axes[0,0].set_title('KS Statistics Distribution')\n",
    "    \n",
    "    # P-values\n",
    "    sns.histplot(p_values, ax=axes[0,1])\n",
    "    axes[0,1].set_title('P-values Distribution')\n",
    "    \n",
    "    # Feature means comparison\n",
    "    sns.scatterplot(x=original_data.mean(), \n",
    "                    y=generated_data.mean(),\n",
    "                    ax=axes[1,0])\n",
    "    axes[1,0].set_title('Feature Means Comparison')\n",
    "    \n",
    "    # Feature STDs comparison\n",
    "    sns.scatterplot(x=original_data.std(), \n",
    "                    y=generated_data.std(),\n",
    "                    ax=axes[1,1])\n",
    "    axes[1,1].set_title('Feature STDs Comparison')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# %% Cross-validation Analysis\n",
    "def analyze_cv_results(cv_results):\n",
    "    \"\"\"\n",
    "    Analyze cross-validation results.\n",
    "    \n",
    "    Args:\n",
    "        cv_results: Dictionary containing CV metrics\n",
    "    \"\"\"\n",
    "    # Plot metrics across folds\n",
    "    metrics = ['generator_loss', 'critic_loss', 'ks_statistic']\n",
    "    \n",
    "    fig, axes = plt.subplots(len(metrics), 1, figsize=(12, 4*len(metrics)))\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        fold_values = [fold[metric] for fold in cv_results.values()]\n",
    "        axes[i].boxplot(fold_values)\n",
    "        axes[i].set_title(f'{metric} Across Folds')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# %% Run Analysis\n",
    "# Load results\n",
    "metrics_tracker = MetricsTracker.load('path_to_metrics')\n",
    "original_data = pd.read_csv('path_to_original_data.csv')\n",
    "generated_data = pd.read_csv('path_to_generated_data.csv')\n",
    "cv_results = pd.read_csv('path_to_cv_results.csv')\n",
    "\n",
    "# Perform analysis\n",
    "analyze_training_metrics(metrics_tracker)\n",
    "analyze_distributions(original_data, generated_data)\n",
    "analyze_cv_results(cv_results)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
