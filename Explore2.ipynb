{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "Data path: data/data_combined_controls.csv\n",
      "Device: cpu\n",
      "Epochs: 20\n",
      "Batch size: 32\n",
      "Learning rate: 0.001\n",
      "Number of folds: 5\n",
      "\n",
      "Loading and processing data...\n",
      "\n",
      "Dataset Information:\n",
      "Original data shape: (23, 8063)\n",
      "Number of features: 8063\n",
      "\n",
      "Feature types:\n",
      "IGKV2.28     float64\n",
      "IGKV3D.20    float64\n",
      "IGKV1.12     float64\n",
      "IGLC7        float64\n",
      "IGKV2.29     float64\n",
      "              ...   \n",
      "ZSCAN32      float64\n",
      "ZSWIM8       float64\n",
      "ZW10         float64\n",
      "ZWILCH       float64\n",
      "ZWINT        float64\n",
      "Length: 8063, dtype: object\n",
      "\n",
      "Training WGAN-GP and generating synthetic samples...\n",
      "\n",
      "Data Overview:\n",
      "Original samples: 23\n",
      "Features: 8063\n",
      "\n",
      "Feature types:\n",
      "IGKV2.28     float64\n",
      "IGKV3D.20    float64\n",
      "IGKV1.12     float64\n",
      "IGLC7        float64\n",
      "IGKV2.29     float64\n",
      "              ...   \n",
      "ZSCAN32      float64\n",
      "ZSWIM8       float64\n",
      "ZW10         float64\n",
      "ZWILCH       float64\n",
      "ZWINT        float64\n",
      "Length: 8063, dtype: object\n",
      "\n",
      "Using device: cpu\n",
      "\n",
      "Processing fold 1/5\n",
      "Training samples: 18\n",
      "Validation samples: 5\n",
      "Train Loader Len: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training WGAN-GP:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20] Batch [0] G_loss: 22.2386 C_loss: -121.8678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training WGAN-GP:   5%|▌         | 1/20 [02:13<42:20, 133.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 Summary:\n",
      "Average G_loss: 16.3637\n",
      "Average C_loss: -318.0577\n",
      "Epoch [1/20] Batch [0] G_loss: -1.6380 C_loss: -39.2811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training WGAN-GP:  10%|█         | 2/20 [04:28<40:22, 134.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Summary:\n",
      "Average G_loss: 33.0520\n",
      "Average C_loss: -394.7652\n",
      "Epoch [2/20] Batch [0] G_loss: 7.2107 C_loss: -97.1136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training WGAN-GP:  15%|█▌        | 3/20 [06:42<38:00, 134.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Summary:\n",
      "Average G_loss: 18.8454\n",
      "Average C_loss: -434.7357\n",
      "Epoch [3/20] Batch [0] G_loss: 0.1051 C_loss: 2.3643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training WGAN-GP:  20%|██        | 4/20 [08:56<35:45, 134.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Summary:\n",
      "Average G_loss: 28.0036\n",
      "Average C_loss: -390.5912\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "WGAN-GP Training and Evaluation Notebook\n",
    "\n",
    "This notebook demonstrates the training and evaluation of WGAN-GP for synthetic data generation.\n",
    "The implementation focuses on the WGAN-GP model, which showed superior performance over\n",
    "VAE and WAE in preliminary testing.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Import local modules\n",
    "from src.models.data_augmentation.GAN import train_and_generate\n",
    "from src.utils.preprocessing import process\n",
    "from src.utils.evaluation import (\n",
    "    compare_statistics,\n",
    "    compare_distributions,\n",
    "    generate_tsne,\n",
    "    recenter_data\n",
    ")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = \"data/data_combined_controls.csv\"\n",
    "RESULTS_DIR = Path(\"results\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "N_SPLITS = 5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Number of folds: {N_SPLITS}\")\n",
    "\n",
    "# Data Loading and Initial Processing\n",
    "print(\"\\nLoading and processing data...\")\n",
    "_, _, scaled_data, scaler, n_features = process(DATA_PATH)\n",
    "\n",
    "print(\"\\nDataset Information:\")\n",
    "print(f\"Original data shape: {scaled_data.shape}\")\n",
    "print(f\"Number of features: {n_features}\")\n",
    "print(\"\\nFeature types:\")\n",
    "print(scaled_data.dtypes)\n",
    "\n",
    "# Generate Synthetic Data\n",
    "print(\"\\nTraining WGAN-GP and generating synthetic samples...\")\n",
    "synthetic_data, original_data = train_and_generate(\n",
    "    filepath=DATA_PATH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    device=DEVICE,\n",
    "    n_splits=N_SPLITS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    save_info=True\n",
    ")\n",
    "\n",
    "# Evaluate Original vs Synthetic Data\n",
    "print(\"\\nEvaluating synthetic data quality...\")\n",
    "\n",
    "# 1. Statistical Comparison\n",
    "stats_comparison = compare_statistics(original_data, synthetic_data)\n",
    "print(\"\\nStatistical Comparison Summary:\")\n",
    "print(stats_comparison.describe())\n",
    "\n",
    "# Save detailed statistics\n",
    "stats_file = RESULTS_DIR / \"statistical_comparison.csv\"\n",
    "stats_comparison.to_csv(stats_file)\n",
    "print(f\"\\nDetailed statistics saved to: {stats_file}\")\n",
    "\n",
    "# 2. Distribution Comparison (KS Test)\n",
    "ks_results = compare_distributions(original_data, synthetic_data)\n",
    "\n",
    "# Plot KS Statistics\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=ks_results, x='KS_Statistic', kde=True)\n",
    "plt.title('Distribution of KS Statistics: Original vs Synthetic Data')\n",
    "plt.xlabel('KS Statistic')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.savefig(RESULTS_DIR / \"ks_statistics_distribution.png\")\n",
    "plt.show()\n",
    "\n",
    "# 3. Feature-wise Visualization\n",
    "print(\"\\nGenerating feature-wise visualizations...\")\n",
    "for column in original_data.columns:\n",
    "    if column not in ['data_type', 'fold', 'sample_id']:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Original data distribution\n",
    "        sns.kdeplot(data=original_data[column], label='Original', alpha=0.6)\n",
    "        # Synthetic data distribution\n",
    "        sns.kdeplot(data=synthetic_data[column], label='Synthetic', alpha=0.6)\n",
    "        \n",
    "        plt.title(f'Distribution Comparison: {column}')\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(RESULTS_DIR / f\"feature_distribution_{column}.png\")\n",
    "        plt.close()\n",
    "\n",
    "# 4. t-SNE Visualization\n",
    "print(\"\\nGenerating t-SNE visualization...\")\n",
    "generate_tsne(original_data, synthetic_data)\n",
    "plt.savefig(RESULTS_DIR / \"tsne_visualization.png\")\n",
    "plt.show()\n",
    "\n",
    "# 5. Summary Statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(\"\\nOriginal Data:\")\n",
    "print(original_data.describe())\n",
    "print(\"\\nSynthetic Data:\")\n",
    "print(synthetic_data.describe())\n",
    "\n",
    "# 6. Quality Metrics\n",
    "print(\"\\nQuality Metrics:\")\n",
    "print(f\"Total features with KS statistic < 0.1: {(ks_results['KS_Statistic'] < 0.1).sum()}\")\n",
    "print(f\"Percentage of well-matched features: {(ks_results['KS_Statistic'] < 0.1).mean()*100:.2f}%\")\n",
    "\n",
    "# Save results\n",
    "results_summary = {\n",
    "    \"n_original_samples\": len(original_data),\n",
    "    \"n_synthetic_samples\": len(synthetic_data),\n",
    "    \"n_features\": n_features,\n",
    "    \"n_folds\": N_SPLITS,\n",
    "    \"mean_ks_statistic\": ks_results['KS_Statistic'].mean(),\n",
    "    \"percent_good_features\": (ks_results['KS_Statistic'] < 0.1).mean()*100\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / \"results_summary.txt\", \"w\", encoding='utf-8') as f:\n",
    "    for key, value in results_summary.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "print(\"\\nAnalysis complete. Results saved in:\", RESULTS_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
